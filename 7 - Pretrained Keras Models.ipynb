{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained Keras Models\n",
    "\n",
    "\n",
    "In this notebook we will go through loading a keras based pretrained model. While the API can sometimes be a little buggy it also has a number of the most powerful pretrained models ready at your disposal with a few lines of code. The ins and outs of using keras for pretrained image detectors is covered here and you should be able to use them in a number of different tasks and integrate them into more complex models by the end of this.\n",
    "\n",
    "For more information on the keras pretrained models visit: https://keras.io/applications/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "## Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.python.keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.applications.vgg16 import decode_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example we will use an image of a cat for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H,W = 224,224\n",
    "img_path = 'cat.jpeg'\n",
    "img = cv2.imread('cat.jpeg')\n",
    "img = cv2.resize(img,(H,W))\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image must be put into a batch shape to be injested by the model\n",
    "shape = __[BATCH SIZE, HEIGHT, WIDTH, COLOR CHANNELS]__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.reshape([1,H,W,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we draw the computational model. Take note of the variable `include_top`. This is the prediction layer, when using the pretrained model on a different task this layer can be discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we draw the computational map of the model.\n",
    "model = VGG16(include_top=True, weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When inputing images into the model they must be preprocessed in the same manner as the model was trained. For different models this can sometimes be slightly different. Keras models come with a 'preprocess_input' function that take care of this for you. Feed an appropriate placeholder into this function to make sure the preprocessing matches the model implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(shape=img.shape, dtype=tf.float32)\n",
    "processed_inputs = preprocess_input(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input the readied data tensor into the model to complete the process. The output tensor in this case will be a prediction. If `include_top = False` in the model declaration then output will be the last feature vector output before prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(processed_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access any intermediate tensor within the model which is inside `model.layers`. By checking the architecture of the particular model (see details at https://keras.io/applications/) these can be more easily accessed by creating a dictionary indexed by tensor name and can be used in conjunction with any additional operations drawn on the computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_layers = {l.name: l.output for l in model.layers}\n",
    "\n",
    "for k,v in model_layers.items():\n",
    "    print(k,'has shape', v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the model with the correct weights a keras backend session must be used. This is because of some gymnastics keras is doing in the background and can be a bit buggy. So be careful to make sure the correct weights are loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.keras.backend.get_session() as sess:\n",
    "    K.set_session(sess)\n",
    "    output = sess.run(pred, feed_dict={inputs: images})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model outputs a prediction for each possible classification outcome, this model is trained on imagenet with 1000 different labels. As in most multi-class classification models we just take the max output as our result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The output has a shape',output.shape)\n",
    "print('First 5 predictions',output[0,:5])\n",
    "print()\n",
    "idx = np.argmax(output[0])\n",
    "print('The largest prediciton label %d has output %.3f.'%(idx,output[0,idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the keras packages to interprete this correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the probabilities to class labels\n",
    "label = decode_predictions(output)\n",
    "# retrieve the most likely result, e.g. highest probability\n",
    "label = label[0][0]\n",
    "# print the classification\n",
    "print('The prediction is %s with %.2f%% certainty.' % (label[1], label[2]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Use the vgg model and fine tune it on the MNIST classification task.\n",
    "\n",
    "Considerations:\n",
    "* The vgg model takes images of size 224,224 and MNIST data is of size 28,28.\n",
    "* A fully connected layer will need to be added onto the vgg model with the correct number of labels for our classification problem.\n",
    "* Which parameters do we want to train, and what should the learning rate be?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
